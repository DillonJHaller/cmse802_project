<h3> Train/test split </h3>

This folder is for the scripts that actually generate the training and testing data in the most Python machine learning friendly format possible. The previous section generates labels, and here, we assign the data to those labels. Satellite data records are enormous. In this case, the raw data I have is almost 1 terabyte. The following scripts, run in order, reduce that data to something more manageable. The manageable data will actually be saved in the GitHub repo so that model implementation can be re-run by anybody.

1. `Generate_train_test_points.py` is used to define the training and testing dataset. The landscape has been comprehensively categorized, but using every single point on it is neither practical nor desirable. Thus, this script takes only a small subset of the points available, 100 for each of the nine trajectories of interest for training and 25 for testing, to preserve a common 4:1 training-to-testing ratio.
2. `Pull_HLS_Data.py` is used to get the feature data from the other large dataset, the Harmonized Landsat Sentinel-2 archive. NOTE: I'm goint to need to do more with this. In the name of getting early implementation done, I'm proceeding with very un-engineered data.